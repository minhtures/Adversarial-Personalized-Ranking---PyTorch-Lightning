{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:03.651893Z",
     "iopub.status.busy": "2024-11-25T14:36:03.651473Z",
     "iopub.status.idle": "2024-11-25T14:36:27.504963Z",
     "shell.execute_reply": "2024-11-25T14:36:27.503620Z",
     "shell.execute_reply.started": "2024-11-25T14:36:03.651862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning\n",
    "! pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:27.507437Z",
     "iopub.status.busy": "2024-11-25T14:36:27.507097Z",
     "iopub.status.idle": "2024-11-25T14:36:38.947262Z",
     "shell.execute_reply": "2024-11-25T14:36:38.946027Z",
     "shell.execute_reply.started": "2024-11-25T14:36:27.507407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar, LearningRateMonitor \n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pandas as pd\n",
    "from torchmetrics.retrieval import RetrievalHitRate, RetrievalNormalizedDCG, RetrievalAUROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:38.949296Z",
     "iopub.status.busy": "2024-11-25T14:36:38.948786Z",
     "iopub.status.idle": "2024-11-25T14:36:38.972793Z",
     "shell.execute_reply": "2024-11-25T14:36:38.971297Z",
     "shell.execute_reply.started": "2024-11-25T14:36:38.949267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BPRData(Dataset):\n",
    "    def __init__(self, df, num_neg=1):\n",
    "        super(BPRData, self).__init__()\n",
    "        self.df = df\n",
    "        if num_neg is not None:\n",
    "            self.num_neg= num_neg\n",
    "        else:\n",
    "            self.num_neg=0\n",
    "        \n",
    "        # load ratings as a dok matrix\n",
    "        self.features = self.df.values\n",
    "\n",
    "        self.user_num = self.features[:,0].max() + 1 # 1 for unknown\n",
    "        self.item_num = self.features[:,1:].max() + 1\n",
    "\n",
    "        self.pos_item = {}\n",
    "        if self.num_neg > 0:\n",
    "            for user in range(self.user_num):\n",
    "                self.pos_item[user] = self.df[self.df['user']==user]['item'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.features[idx][0]\n",
    "        item = self.features[idx][1:] # positive\n",
    "        \n",
    "        user = max(0, min(user,self.user_num))\n",
    "        item = [max(0, min(i,self.item_num)) for i in item]\n",
    "        \n",
    "        if len(item) == 1 and self.num_neg >0:\n",
    "            pos = self.pos_item[user]\n",
    "            pos_i = torch.randint(0, len(pos)+1, (self.num_neg,))\n",
    "            pos.append(0)\n",
    "            pos.append(self.item_num)\n",
    "            pos, _  = torch.sort(torch.tensor(pos))\n",
    "            for j in pos_i:\n",
    "                low = pos[j]\n",
    "                high = pos[j+1]\n",
    "                if low < high:\n",
    "                    item_j = int(torch.randint(low, high,(1,))[0])\n",
    "                else:\n",
    "                    item_j = 0       # <UNK>\n",
    "                item.append(item_j)\n",
    "        return user, torch.tensor(item)\n",
    "    \n",
    "def collate_data(batch):\n",
    "    user, item  = zip(*batch)\n",
    "    user = torch.tensor(user)\n",
    "    item = torch.nn.utils.rnn.pad_sequence(item, batch_first=True)\n",
    "    item= torch.nan_to_num(item)\n",
    "\n",
    "    return user, item\n",
    "\n",
    "class BPRDataModule(LightningDataModule):\n",
    "    def __init__(self, data_path, tr_neg=1, val_neg=99, tr_bs=128, val_bs=32, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_path\n",
    "        self.tr_neg = tr_neg\n",
    "        self.val_neg = val_neg\n",
    "        self.tr_bs = tr_bs\n",
    "        self.val_bs = val_bs\n",
    "        self.num_workers = num_workers\n",
    "        self.get_data()\n",
    "        \n",
    "    def get_data(self):    \n",
    "        self.df_train = pd.read_csv(self.data_dir+'.train.rating', usecols=[0,1], sep='\\t', names = ['user', 'item'])\n",
    "        self.df_val = pd.read_csv(self.data_dir+'.test.rating', usecols=[0,1], sep='\\t', names = ['user', 'item'])\n",
    "        self.df_test = pd.read_csv(self.data_dir+'.test.negative', sep='\\t', names = ['user', 'item']+[f'item_neg_{i+1}' for i in range(99)])\n",
    "        self.df_test['user'] = [t[1] for t in self.df_test['user']]\n",
    "        \n",
    "        self.number_user = self.df_train['user'].max()\n",
    "        self.number_item = self.df_train['item'].max()\n",
    "        self.get_df_info()\n",
    "        \n",
    "    def get_df_info(self):    \n",
    "        print(self.df_train.describe())\n",
    "        print(self.df_train.head())\n",
    "        print(self.df_val.head())\n",
    "        print(self.df_test.head())\n",
    "        \n",
    "        number_interaction = len(self.df_train)\n",
    "        sparsity = 100 - 100.0*number_interaction/ (self.number_user*self.number_user)\n",
    "        print(f'Number of users {self.number_user}')\n",
    "        print(f'Number of items {self.number_item}')\n",
    "        print(f'Number of interactions {number_interaction}')\n",
    "        print(f'Sparsity {sparsity:6f}')\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            self.train_ds = BPRData(self.df_train, num_neg=self.tr_neg)\n",
    "            self.val_ds = BPRData(self.df_val, num_neg=self.val_neg)\n",
    "        if stage == \"test\" or stage == \"predict\":\n",
    "            self.test_ds = BPRData(self.df_val, num_neg=99)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.tr_bs, \n",
    "                          num_workers=self.num_workers ,shuffle=True, collate_fn = collate_data)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.val_bs, \n",
    "                          num_workers=self.num_workers ,shuffle=False, collate_fn = collate_data)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.val_bs, \n",
    "                          num_workers=self.num_workers ,shuffle=False, collate_fn = collate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:38.977341Z",
     "iopub.status.busy": "2024-11-25T14:36:38.976673Z",
     "iopub.status.idle": "2024-11-25T14:36:40.085327Z",
     "shell.execute_reply": "2024-11-25T14:36:40.084110Z",
     "shell.execute_reply.started": "2024-11-25T14:36:38.977311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movielens_1m = '/kaggle/input/movielens-1m/ml-1m'\n",
    "yelp = '/kaggle/input/yelp-dataset/yelp'\n",
    "pinterest ='/kaggle/input/pinterest-20/pinterest-20'\n",
    "data_config = {\n",
    "    'tr_neg':1, \n",
    "    'val_neg':99, \n",
    "    'tr_bs': 256, \n",
    "    'val_bs': 128, \n",
    "    'num_workers':4\n",
    "}\n",
    "dm = BPRDataModule(yelp, **data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:40.086998Z",
     "iopub.status.busy": "2024-11-25T14:36:40.086677Z",
     "iopub.status.idle": "2024-11-25T14:36:40.094632Z",
     "shell.execute_reply": "2024-11-25T14:36:40.093554Z",
     "shell.execute_reply.started": "2024-11-25T14:36:40.086972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bpr_loss(prediction):\n",
    "    prediction_i = prediction[:,0].reshape(-1,1)\n",
    "    prediction_j = prediction[:,1:]\n",
    "    loss = - torch.nn.functional.logsigmoid(prediction_i - prediction_j).mean()\n",
    "    return loss\n",
    "\n",
    "def batch_NDCG(prediction, top_k=10):\n",
    "    \"\"\"\n",
    "    prediction: num_user x num_item\n",
    "    each user has one postive item, indicated by 'positive'\n",
    "    NDCG = log(2)/log(rank+1) if rank <=topk\n",
    "    \"\"\"\n",
    "    positive_score = prediction[:,0].reshape(-1,1)\n",
    "    rank = (prediction - positive_score) > 0\n",
    "    rank = rank.to(torch.int).sum(dim=-1)            # rank >=0\n",
    "\n",
    "    mask = (rank < top_k).to(torch.int)         # NDCG <0 if rank>top_k  \n",
    "    NDCG = torch.log(torch.tensor(2.0)) / (torch.log(rank + 2.0))\n",
    "    NDCG *= mask\n",
    "\n",
    "    return NDCG.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:40.096769Z",
     "iopub.status.busy": "2024-11-25T14:36:40.096310Z",
     "iopub.status.idle": "2024-11-25T14:36:40.119990Z",
     "shell.execute_reply": "2024-11-25T14:36:40.118888Z",
     "shell.execute_reply.started": "2024-11-25T14:36:40.096738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BPR(LightningModule):\n",
    "    def __init__(self, user_num, item_num, embed_size, optimizer=None, scheduler=None,  \n",
    "                 top_k=10, eps=0.1, reg = 0.0, reg_adv=0.0):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        user_num: number of users;\n",
    "        item_num: number of items;\n",
    "        embed_size: number of predictive factors.\n",
    "        \"\"\"        \n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.embed_size = embed_size\n",
    "        self.top_k=top_k\n",
    "        self.eps=eps\n",
    "        self.reg=reg\n",
    "        self.reg_adv=reg_adv\n",
    "\n",
    "        self.embed_user = nn.Embedding(self.user_num, self.embed_size)\n",
    "        self.embed_item = nn.Embedding(self.item_num, self.embed_size)\n",
    "        \n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "        self.optimizer_config = optimizer\n",
    "        self.schedulerr_config = scheduler\n",
    "        self.save_hyperparameters()\n",
    "     \n",
    "    def forward(self, user, item):\n",
    "        user_embed = self.embed_user(user)       # N x in\n",
    "        item_embed = self.embed_item(item)       # N x (1+neg) x in\n",
    "        # N x 1 x in  * N x in x (1+neg) => N x (1+neg)\n",
    "        prediction = torch.bmm(user_embed.unsqueeze(1), item_embed.transpose(1,2)).squeeze(1)\n",
    "            \n",
    "        return prediction, user_embed, item_embed\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_adversarial(self, user, item, user_embed, item_embed):\n",
    "        grad_user = torch.index_select(self.embed_user.weight.grad.clone(), 0, user) \n",
    "        grad_item = torch.index_select(self.embed_item.weight.grad.clone(), 0, item.flatten()).reshape(item.size(0), item.size(1),-1)\n",
    "\n",
    "        # normalization: new_grad = (grad / |grad|) * eps\n",
    "        delta_user = self.eps * nn.functional.normalize(grad_user, p=2, dim=-1)\n",
    "        delta_item = self.eps * nn.functional.normalize(grad_item, p=2, dim=-1)\n",
    "\n",
    "        delta_user = torch.max(user_embed.abs(), dim=0, keepdim=True)[0] * delta_user\n",
    "        delta_item = torch.max(item_embed.abs(), dim=0, keepdim=True)[0] * delta_item\n",
    "\n",
    "        return delta_user, delta_item\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        user, item = batch\n",
    "        opt = self.optimizers()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        self.embed_user.weight.retain_grad()\n",
    "        self.embed_item.weight.retain_grad()\n",
    "        \n",
    "        prediction, user_embed, item_embed = self(user,item)\n",
    "        \n",
    "        loss = bpr_loss(prediction)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        reg = torch.linalg.norm(user_embed, dim =-1).mean() + torch.linalg.norm(item_embed, dim =-1).mean()\n",
    "        self.log(\"train_reg_loss\", reg, prog_bar=True)\n",
    "        loss += self.reg * reg\n",
    "        \n",
    "        if self.reg_adv > 0:\n",
    "            self.manual_backward(loss,retain_graph=True)    \n",
    "            delta_user, delta_item = self._get_adversarial(user, item, user_embed, item_embed)\n",
    "            \n",
    "            user_adv = user_embed + delta_user\n",
    "            item_adv = item_embed + delta_item\n",
    "            \n",
    "            pred_adv = torch.bmm(user_adv.unsqueeze(1), item_adv.transpose(1,2)).squeeze(1)\n",
    "            \n",
    "            loss_adv = bpr_loss(pred_adv)\n",
    "            self.log(\"train_adv_loss\", loss_adv, prog_bar=True)\n",
    "            reg_adv = torch.linalg.norm(user_adv, dim =-1).mean() + torch.linalg.norm(item_adv, dim =-1).mean()\n",
    "            self.log(\"train_reg_adv_loss\", reg_adv, prog_bar=True)\n",
    "            \n",
    "            loss_adv = self.reg_adv*(loss_adv + self.reg * reg_adv)\n",
    "            self.manual_backward(loss_adv)  \n",
    "        else:\n",
    "            self.manual_backward(loss)  \n",
    "            \n",
    "        opt.step()\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user, item = batch\n",
    "        \n",
    "        prediction, user_embed, item_embed = self(user,item)\n",
    "        \n",
    "        loss = bpr_loss(prediction)\n",
    "        self.log(\"bpr_loss\", loss, prog_bar=True)\n",
    "        reg = torch.linalg.norm(user_embed, dim =-1).mean() + torch.linalg.norm(item_embed, dim =-1).mean()\n",
    "        self.log(\"reg_loss\", reg, prog_bar=True)\n",
    "        loss += self.reg * reg\n",
    "        \n",
    "        ndcg = batch_NDCG(prediction, self.top_k)\n",
    "        self.log(\"ndcg\", ndcg, prog_bar=True)\n",
    "        return loss \n",
    "      \n",
    "    def predict_step(self, batch):\n",
    "        user, item = batch\n",
    "        prediction, user_embed, item_embed = self(user,item)\n",
    "        return prediction\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer_config is None:\n",
    "            optimizer = torch.optim.AdamW(self.parameters())\n",
    "        else:\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), **self.optimizer_config)\n",
    "        if self.schedulerr_config is None:\n",
    "            return optimizer\n",
    "        else:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, **self.schedulerr_config)\n",
    "            return {\n",
    "                'optimizer': optimizer,\n",
    "                'lr_scheduler': {\n",
    "                    'scheduler': scheduler,\n",
    "                    'interval': 'step'\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:40.121981Z",
     "iopub.status.busy": "2024-11-25T14:36:40.121567Z",
     "iopub.status.idle": "2024-11-25T14:36:40.140974Z",
     "shell.execute_reply": "2024-11-25T14:36:40.139465Z",
     "shell.execute_reply.started": "2024-11-25T14:36:40.121944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_param ={\n",
    "    'user_num' : dm.number_user + 1,  # 1 for unknown\n",
    "    'item_num' : dm.number_item + 1, \n",
    "    'embed_size' : 64  ,\n",
    "    \"top_k\" : 10,\n",
    "}\n",
    "BPR_param = {\n",
    "    \"reg\" : 0.01,\n",
    "    \"eps\" : 0,\n",
    "    \"reg_adv\" : 0,\n",
    "    'optimizer': { \n",
    "        'lr' : 0.01, \n",
    "        'betas' : [0.9,0.999], \n",
    "        'weight_decay' : 1e-2, \n",
    "        'eps' : 1e-9,        \n",
    "    },\n",
    "    'scheduler': {\n",
    "        'T_0' : 2000, \n",
    "        'T_mult' : 2, \n",
    "        'eta_min' : 0.001,\n",
    "    }\n",
    "}\n",
    "\n",
    "APR_param = {\n",
    "    \"reg\": 0.01,\n",
    "    \"eps\": 0.5,\n",
    "    \"reg_adv\" : 1.0,\n",
    "    'optimizer': { \n",
    "        'lr' : 0.003, \n",
    "        'betas' : [0.9,0.999], \n",
    "        'weight_decay' : 1e-2, \n",
    "        'eps' : 1e-9,        \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:40.143550Z",
     "iopub.status.busy": "2024-11-25T14:36:40.143102Z",
     "iopub.status.idle": "2024-11-25T14:36:40.188211Z",
     "shell.execute_reply": "2024-11-25T14:36:40.187062Z",
     "shell.execute_reply.started": "2024-11-25T14:36:40.143509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accelerator = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        filename='{epoch}-{ndcg:.4f}',\n",
    "        save_top_k = 5,\n",
    "        monitor ='ndcg',\n",
    "        mode='max',\n",
    "        )\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "progress_bar = RichProgressBar()\n",
    "\n",
    "# callbacks = [checkpoint_callback, progress_bar, lr_monitor]\n",
    "callbacks = [checkpoint_callback, lr_monitor]\n",
    "\n",
    "param = {\n",
    "    'max_epochs': 50,\n",
    "    # 'overfit_batches': 64,\n",
    "    'devices':\"auto\", 'accelerator': accelerator,\n",
    "    \"log_every_n_steps\": 20,\n",
    "    \"callbacks\": callbacks,\n",
    "    'reload_dataloaders_every_n_epochs': 1, \n",
    "     \"logger\" : TensorBoardLogger(save_dir=\"exp\", name=\"BPR\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:36:40.189901Z",
     "iopub.status.busy": "2024-11-25T14:36:40.189598Z",
     "iopub.status.idle": "2024-11-25T14:39:13.376305Z",
     "shell.execute_reply": "2024-11-25T14:39:13.374837Z",
     "shell.execute_reply.started": "2024-11-25T14:36:40.189876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_param = base_param\n",
    "_param.update(BPR_param)\n",
    "\n",
    "model = BPR(**_param)\n",
    "trainer = Trainer(**param)\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:39:13.380897Z",
     "iopub.status.busy": "2024-11-25T14:39:13.380529Z",
     "iopub.status.idle": "2024-11-25T14:39:15.844528Z",
     "shell.execute_reply": "2024-11-25T14:39:15.842811Z",
     "shell.execute_reply.started": "2024-11-25T14:39:13.380862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! realpath exp/BPR/*/checkpoints/epoch=*.ckpt\n",
    "! cp `realpath exp/BPR/*/checkpoints/epoch=*.ckpt | tail -n 1` best_BPR.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:39:15.847103Z",
     "iopub.status.busy": "2024-11-25T14:39:15.846652Z",
     "iopub.status.idle": "2024-11-25T14:39:15.857453Z",
     "shell.execute_reply": "2024-11-25T14:39:15.856216Z",
     "shell.execute_reply.started": "2024-11-25T14:39:15.847066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        filename='{epoch}-{ndcg:.4f}',\n",
    "        save_top_k = 5,\n",
    "        monitor ='ndcg',\n",
    "        mode='max',\n",
    "        )\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "progress_bar = RichProgressBar()\n",
    "\n",
    "# callbacks = [checkpoint_callback, progress_bar, lr_monitor]\n",
    "callbacks = [checkpoint_callback, lr_monitor]\n",
    "\n",
    "param = {\n",
    "    'max_epochs': 25,\n",
    "    # 'overfit_batches': 64,\n",
    "    'devices':\"auto\", 'accelerator': accelerator,\n",
    "    \"log_every_n_steps\": 20,\n",
    "    \"callbacks\": callbacks,\n",
    "    'reload_dataloaders_every_n_epochs': 1, \n",
    "     \"logger\" : TensorBoardLogger(save_dir=\"exp\", name=\"APR\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:39:15.859274Z",
     "iopub.status.busy": "2024-11-25T14:39:15.858957Z",
     "iopub.status.idle": "2024-11-25T14:40:35.773119Z",
     "shell.execute_reply": "2024-11-25T14:40:35.771981Z",
     "shell.execute_reply.started": "2024-11-25T14:39:15.859232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_param = base_param\n",
    "_param.update(APR_param)\n",
    "\n",
    "model = BPR.load_from_checkpoint('best_BPR.ckpt', **_param)\n",
    "trainer = Trainer(**param)\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:40:35.775479Z",
     "iopub.status.busy": "2024-11-25T14:40:35.775020Z",
     "iopub.status.idle": "2024-11-25T14:40:38.222411Z",
     "shell.execute_reply": "2024-11-25T14:40:38.220889Z",
     "shell.execute_reply.started": "2024-11-25T14:40:35.775432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! realpath exp/APR/*/checkpoints/epoch=*.ckpt\n",
    "! cp `realpath exp/APR/*/checkpoints/epoch=*.ckpt | tail -n 1` best_APR.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:48:43.504976Z",
     "iopub.status.busy": "2024-11-25T14:48:43.504591Z",
     "iopub.status.idle": "2024-11-25T14:48:43.515468Z",
     "shell.execute_reply": "2024-11-25T14:48:43.514211Z",
     "shell.execute_reply.started": "2024-11-25T14:48:43.504949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, dm):\n",
    "    preds = trainer.predict(model, dm)\n",
    "    preds= torch.cat(preds,dim=0).flatten()\n",
    "    index = torch.tensor(dm.test_ds.df['user']).repeat_interleave(dm.test_ds.num_neg + 1)\n",
    "    target = torch.tensor([True]+ [False]*dm.val_neg).repeat(len(dm.test_ds.df))\n",
    "    \n",
    "    for top_k in range(1,10):\n",
    "        metric_hr = RetrievalHitRate(top_k=top_k)\n",
    "        metric_ndcg = RetrievalNormalizedDCG(top_k=top_k)\n",
    "        metric_auroc = RetrievalAUROC(top_k=top_k)\n",
    "    \n",
    "        \n",
    "        hr = metric_hr(preds, target, indexes=index)\n",
    "        ndcg = metric_ndcg(preds, target, indexes=index)\n",
    "        auroc = metric_auroc(preds, target, indexes=index)\n",
    "        \n",
    "        print(f\"top {top_k:d} : hr: {hr:.3f}, ndcg: {ndcg:.3f}, auroc: {auroc:.3f}\")\n",
    "        \n",
    "    for top_k in range(10,100+1,10):\n",
    "        metric_hr = RetrievalHitRate(top_k=top_k)\n",
    "        metric_ndcg = RetrievalNormalizedDCG(top_k=top_k)\n",
    "        metric_auroc = RetrievalAUROC(top_k=top_k)\n",
    "    \n",
    "        \n",
    "        hr = metric_hr(preds, target, indexes=index)\n",
    "        ndcg = metric_ndcg(preds, target, indexes=index)\n",
    "        auroc = metric_auroc(preds, target, indexes=index)\n",
    "        \n",
    "        print(f\"top {top_k:d} : hr: {hr:.3f}, ndcg: {ndcg:.3f}, auroc: {auroc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:48:44.184324Z",
     "iopub.status.busy": "2024-11-25T14:48:44.183984Z",
     "iopub.status.idle": "2024-11-25T14:48:44.427100Z",
     "shell.execute_reply": "2024-11-25T14:48:44.425742Z",
     "shell.execute_reply.started": "2024-11-25T14:48:44.184299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BPR_model = BPR.load_from_checkpoint('best_BPR.ckpt', **_param)\n",
    "APR_model = BPR.load_from_checkpoint('best_APR.ckpt', **_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:48:48.185376Z",
     "iopub.status.busy": "2024-11-25T14:48:48.184981Z",
     "iopub.status.idle": "2024-11-25T14:56:38.178557Z",
     "shell.execute_reply": "2024-11-25T14:56:38.177253Z",
     "shell.execute_reply.started": "2024-11-25T14:48:48.185344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_model(BPR_model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T14:56:38.181242Z",
     "iopub.status.busy": "2024-11-25T14:56:38.180881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_model(APR_model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 339,
     "sourceId": 77759,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 616982,
     "sourceId": 1102461,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4758316,
     "sourceId": 8065459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4758322,
     "sourceId": 8065467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4758328,
     "sourceId": 8065473,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4758585,
     "sourceId": 8075448,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
